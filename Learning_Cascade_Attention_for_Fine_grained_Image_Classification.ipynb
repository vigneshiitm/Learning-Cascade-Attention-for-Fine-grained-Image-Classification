{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning Cascade Attention for Fine-grained Image Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpFY1sZUCoBIK61n2+IMRY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vigneshiitm/Learning-Cascade-Attention-for-Fine-grained-Image-Classification/blob/main/Learning_Cascade_Attention_for_Fine_grained_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOE_8WVIcHg0"
      },
      "source": [
        "import keras.initializers as KI\r\n",
        "import keras.layers as KL\r\n",
        "import keras.losses as KLoss\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras.engine.topology import Layer\r\n",
        "from keras.layers import Convolution2D, GlobalAveragePooling2D, Dense\r\n",
        "from keras.models import Model\r\n",
        "from keras.utils import conv_utils\r\n",
        "from keras import applications\r\n",
        "#from keras.utils.conv_utils import normalize_data_format\r\n",
        "\r\n",
        "import keras.backend as K\r\n",
        "def normalize_data_format(value):\r\n",
        "    if value is None:\r\n",
        "        value = K.image_data_format()\r\n",
        "    data_format = value.lower()\r\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\r\n",
        "        raise ValueError('The `data_format` argument must be one of '\r\n",
        "                         '\"channels_first\", \"channels_last\". Received: ' +\r\n",
        "                         str(value))\r\n",
        "    return data_format\r\n",
        "\r\n",
        "class GlobalAttentionPooling2D(Layer):\r\n",
        "    def __init__(self, data_format=None, **kwargs):\r\n",
        "        super(GlobalAttentionPooling2D, self).__init__(**kwargs)\r\n",
        "        self.data_format = normalize_data_format(data_format)\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        input_shape = input_shape[0]\r\n",
        "        if self.data_format == 'channels_last':\r\n",
        "            return (input_shape[0], input_shape[3])\r\n",
        "        else:\r\n",
        "            return (input_shape[0], input_shape[1])\r\n",
        "\r\n",
        "    def call(self, inputs, **kwargs):\r\n",
        "        inputs_s = inputs[0]\r\n",
        "        inputs_m = inputs[1]\r\n",
        "\r\n",
        "        shape = tuple(inputs_s.get_shape().as_list())\r\n",
        "\r\n",
        "        outputs_s = tf.multiply(inputs_s, inputs_m)\r\n",
        "        outputs_m = K.repeat_elements(inputs_m, shape[-1], axis=-1)\r\n",
        "\r\n",
        "        outputs_s = K.sum(outputs_s, axis=[1, 2])\r\n",
        "        outputs_m = K.sum(outputs_m, axis=[1, 2])\r\n",
        "\r\n",
        "        outputs = outputs_s / outputs_m\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "        config = {'data_format': self.data_format}\r\n",
        "        base_config = super(GlobalAttentionPooling2D, self).get_config()\r\n",
        "        return dict(list(base_config.items()) + list(config.items()))\r\n",
        "\r\n",
        "\r\n",
        "def spatial_mask_generate(S, y_old, height, width, name='', mask_max=2. / 3, mask_min=1. / 3, init_bias=-0.5,\r\n",
        "                          s_mask_max=9. / 10, s_mask_min=7. / 10):\r\n",
        "    y_old_w = KL.Lambda(lambda t: K.expand_dims(t, axis=1))(y_old)\r\n",
        "    y_old_w = KL.Lambda(lambda t: K.expand_dims(t, axis=1))(y_old_w)\r\n",
        "    y_old_w = KL.Lambda(lambda t: K.repeat_elements(t, rep=height, axis=1))(y_old_w)\r\n",
        "    y_old_w = KL.Lambda(lambda t: K.repeat_elements(t, rep=width, axis=2))(y_old_w)\r\n",
        "\r\n",
        "    S = KL.Lambda(lambda t: t - K.min(t, axis=-1, keepdims=True))(S)\r\n",
        "\r\n",
        "    M = KL.multiply([S, y_old_w])\r\n",
        "    M = KL.Lambda(lambda t: K.sum(t, axis=-1))(M)\r\n",
        "\r\n",
        "    S_and = KL.Lambda(lambda t: K.mean(t, axis=-1, keepdims=True))(S)\r\n",
        "    S_and = KL.Conv2D(1, (1, 1), activation='tanh',\r\n",
        "                      name='scale_transform_s_and_1' + name, kernel_initializer=KI.Constant(value=1),\r\n",
        "                      bias_initializer=KI.Constant(value=init_bias))(S_and)\r\n",
        "    S_and = KL.Conv2D(1, (1, 1), activation='sigmoid',\r\n",
        "                      name='scale_transform_s_and_2' + name, kernel_initializer=KI.Constant(value=10),\r\n",
        "                      bias_initializer=KI.Constant(value=3))(S_and)\r\n",
        "\r\n",
        "    M = KL.Lambda(lambda t: K.expand_dims(t, axis=-1))(M)\r\n",
        "    M = KL.multiply([M, S_and])\r\n",
        "\r\n",
        "    M = KL.Conv2D(1, (1, 1), name='scale_transform_1' + name, kernel_initializer=KI.Constant(value=1),\r\n",
        "                  bias_initializer=KI.Constant(value=init_bias), activation='tanh')(M)\r\n",
        "    M = KL.Conv2D(1, (1, 1), name='scale_transform_2' + name, kernel_initializer=KI.Constant(value=10),\r\n",
        "                  bias_initializer=KI.Constant(value=3))(M)  # use median and mean?\r\n",
        "    M = KL.Lambda(lambda t: K.sigmoid(t), name='mask' + name)(M)\r\n",
        "\r\n",
        "    M_loss = KL.Lambda(lambda t: spatial_mask_loss(t, max_value=mask_max, min_value=mask_min), name='M_loss' + name)(M)\r\n",
        "    S_and_loss = KL.Lambda(lambda t: spatial_mask_loss(t, max_value=s_mask_max, min_value=s_mask_min),\r\n",
        "                           name='S_and_loss' + name)(S_and)\r\n",
        "    return M, M_loss, S_and_loss\r\n",
        "\r\n",
        "\r\n",
        "def spatial_mask_loss(mask, max_value=4. / 5, min_value=1. / 3):\r\n",
        "    length = K.cast(K.shape(mask)[1] * K.shape(mask)[2], dtype='float32')\r\n",
        "    sum_value = K.sum(mask, axis=[1, 2])\r\n",
        "\r\n",
        "    low_loss = K.maximum(min_value * length - sum_value, 0)\r\n",
        "    high_loss = K.maximum(sum_value - max_value * length, 0)\r\n",
        "\r\n",
        "    final_loss = high_loss + low_loss\r\n",
        "    final_loss = final_loss / length\r\n",
        "\r\n",
        "    return final_loss\r\n",
        "\r\n",
        "\r\n",
        "def rank_transform(t):\r\n",
        "    t = K.stack(t)\r\n",
        "    t = tf.transpose(t, [1, 0, 2])\r\n",
        "    return t\r\n",
        "\r\n",
        "\r\n",
        "def rank_loss(y_true, y_pred):\r\n",
        "    margin = 0.05\r\n",
        "    satisfy = 0.7\r\n",
        "    y_pred = tf.transpose(y_pred, [1, 0, 2])\r\n",
        "    y_true = tf.squeeze(y_true, axis=[2])\r\n",
        "    p1 = y_pred[0]\r\n",
        "    p2 = y_pred[1]\r\n",
        "    p1 = tf.multiply(p1, y_true)\r\n",
        "    p2 = tf.multiply(p2, y_true)\r\n",
        "    p1m = K.max(p1, axis=-1)\r\n",
        "    p2m = K.max(p2, axis=-1)\r\n",
        "    rank1 = K.maximum(0.0, p1m - p2m + margin)\r\n",
        "    rank2 = K.maximum(0.0, -(p1m + p2m - 2 * satisfy))\r\n",
        "    rank = K.minimum(rank1, rank2)\r\n",
        "    return rank\r\n",
        "\r\n",
        "\r\n",
        "def cross_network_similarity_loss(y_true, y_pred):\r\n",
        "    y_pred = tf.transpose(y_pred, [1, 0, 2])\r\n",
        "    p1 = y_pred[0]\r\n",
        "    p2 = y_pred[1]\r\n",
        "    kl = KLoss.kullback_leibler_divergence(p1, p2)\r\n",
        "    return tf.maximum(0.0, kl - 0.15)\r\n",
        "\r\n",
        "\r\n",
        "def entropy(pk):\r\n",
        "    pk = pk + 0.00001\r\n",
        "    e = -tf.reduce_sum(pk * tf.math.log(pk), axis=1)\r\n",
        "    return e\r\n",
        "\r\n",
        "\r\n",
        "def entropy_add(t):\r\n",
        "    A1 = t[0]\r\n",
        "    A2 = t[1]\r\n",
        "    pk1 = t[2]\r\n",
        "    pk2 = t[3]\r\n",
        "    e1 = entropy(pk1)\r\n",
        "    e2 = entropy(pk2)\r\n",
        "    mp1 = e2 / (e1 + e2)\r\n",
        "    mp2 = 1 - mp1\r\n",
        "    mp1 = tf.expand_dims(mp1, axis=1)\r\n",
        "    mp2 = tf.expand_dims(mp2, axis=1)\r\n",
        "    A1 = A1 * mp1\r\n",
        "    A2 = A2 * mp2\r\n",
        "    A = (A1 + A2) * 2\r\n",
        "    return A\r\n",
        "\r\n",
        "\r\n",
        "def build_global_attention_pooling_model_cascade_attention(base_network, class_num):\r\n",
        "    height, width, depth = base_network[0].output_shape[1:]\r\n",
        "\r\n",
        "    feature_map_step_1 = base_network[0].output\r\n",
        "\r\n",
        "    S = Convolution2D(class_num, (1, 1), name='conv_class')(feature_map_step_1)\r\n",
        "    A = GlobalAveragePooling2D()(S)\r\n",
        "\r\n",
        "    y_old = KL.Softmax(name='output_1')(A)\r\n",
        "    M, M_loss, S_and_loss = spatial_mask_generate(S, y_old, height, width, mask_max=1. / 2, mask_min=1. / 4)\r\n",
        "\r\n",
        "    feature_map_step_2 = base_network[1].output\r\n",
        "\r\n",
        "    S_new = Convolution2D(class_num, (1, 1), name='conv_class_filtered')(feature_map_step_2)\r\n",
        "    A_new = GlobalAttentionPooling2D()([S_new, M])\r\n",
        "\r\n",
        "    y_new = KL.Softmax(name='output_2')(A_new)\r\n",
        "\r\n",
        "    r_loss = KL.Lambda(lambda t: rank_transform(t), name='Rank_loss')([y_old, y_new])\r\n",
        "    cns_loss = KL.Lambda(lambda t: t, name='Cross_network_similarity_loss')(r_loss)\r\n",
        "\r\n",
        "    x = KL.concatenate([feature_map_step_1, feature_map_step_2])\r\n",
        "    x = GlobalAveragePooling2D()(x)\r\n",
        "\r\n",
        "    x = Dense(1024, activation='relu')(x)\r\n",
        "    x = Dense(class_num)(x)\r\n",
        "    y_all = KL.Softmax(name='output_3')(x)\r\n",
        "\r\n",
        "    A_final = KL.Lambda(lambda t: entropy_add(t))([x, A_new, y_all, y_new])\r\n",
        "    # output_5 is the final output\r\n",
        "    y = KL.Softmax(name='output_5')(A_final)\r\n",
        "\r\n",
        "    r2_loss = KL.Lambda(lambda t: rank_transform(t), name='Rank_2_loss')([y_old, y])\r\n",
        "    r3_loss = KL.Lambda(lambda t: rank_transform(t), name='Rank_3_loss')([y_new, y])\r\n",
        "\r\n",
        "    for layer in base_network[1].layers:\r\n",
        "        layer._name = layer.name + str(\"_2\")\r\n",
        "\r\n",
        "    model = Model(inputs=[base_network[0].input, base_network[1].input],\r\n",
        "                  outputs=[y_old, y_new, y_all, y, M_loss, S_and_loss,\r\n",
        "                           r_loss, cns_loss,\r\n",
        "                           r2_loss, r3_loss\r\n",
        "                           ])\r\n",
        "\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXjeHw9rc28f"
      },
      "source": [
        "def create_model():\r\n",
        "    modelvgg = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\r\n",
        "    modelvgg2 = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))   \r\n",
        "    model = build_global_attention_pooling_model_cascade_attention([modelvgg, modelvgg2], 10)\r\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMLFmbwhdNRO",
        "outputId": "1a2a99bf-459a-4c50-8bd5-24ba47e08388"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1316 (Conv2D)            (None, 111, 111, 32) 864         input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1316 (Batch (None, 111, 111, 32) 96          conv2d_1316[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1316 (Activation)    (None, 111, 111, 32) 0           batch_normalization_1316[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1317 (Conv2D)            (None, 109, 109, 32) 9216        activation_1316[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1317 (Batch (None, 109, 109, 32) 96          conv2d_1317[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1317 (Activation)    (None, 109, 109, 32) 0           batch_normalization_1317[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1318 (Conv2D)            (None, 109, 109, 64) 18432       activation_1317[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1318 (Batch (None, 109, 109, 64) 192         conv2d_1318[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1318 (Activation)    (None, 109, 109, 64) 0           batch_normalization_1318[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling2D) (None, 54, 54, 64)   0           activation_1318[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1319 (Conv2D)            (None, 54, 54, 80)   5120        max_pooling2d_56[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_16_2 (InputLayer)         [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1319 (Batch (None, 54, 54, 80)   240         conv2d_1319[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1410_2 (Conv2D)          (None, 111, 111, 32) 864         input_16_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1319 (Activation)    (None, 54, 54, 80)   0           batch_normalization_1319[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1410_2 (Bat (None, 111, 111, 32) 96          conv2d_1410_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1320 (Conv2D)            (None, 52, 52, 192)  138240      activation_1319[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1410_2 (Activation)  (None, 111, 111, 32) 0           batch_normalization_1410_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1320 (Batch (None, 52, 52, 192)  576         conv2d_1320[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1411_2 (Conv2D)          (None, 109, 109, 32) 9216        activation_1410_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1320 (Activation)    (None, 52, 52, 192)  0           batch_normalization_1320[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1411_2 (Bat (None, 109, 109, 32) 96          conv2d_1411_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling2D) (None, 25, 25, 192)  0           activation_1320[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1411_2 (Activation)  (None, 109, 109, 32) 0           batch_normalization_1411_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1324 (Conv2D)            (None, 25, 25, 64)   12288       max_pooling2d_57[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1412_2 (Conv2D)          (None, 109, 109, 64) 18432       activation_1411_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1324 (Batch (None, 25, 25, 64)   192         conv2d_1324[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1412_2 (Bat (None, 109, 109, 64) 192         conv2d_1412_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1324 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1324[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1412_2 (Activation)  (None, 109, 109, 64) 0           batch_normalization_1412_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1322 (Conv2D)            (None, 25, 25, 48)   9216        max_pooling2d_57[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1325 (Conv2D)            (None, 25, 25, 96)   55296       activation_1324[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_60_2 (MaxPooling2 (None, 54, 54, 64)   0           activation_1412_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1322 (Batch (None, 25, 25, 48)   144         conv2d_1322[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1325 (Batch (None, 25, 25, 96)   288         conv2d_1325[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1413_2 (Conv2D)          (None, 54, 54, 80)   5120        max_pooling2d_60_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1322 (Activation)    (None, 25, 25, 48)   0           batch_normalization_1322[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1325 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1325[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_126 (AverageP (None, 25, 25, 192)  0           max_pooling2d_57[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1413_2 (Bat (None, 54, 54, 80)   240         conv2d_1413_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1321 (Conv2D)            (None, 25, 25, 64)   12288       max_pooling2d_57[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1323 (Conv2D)            (None, 25, 25, 64)   76800       activation_1322[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1326 (Conv2D)            (None, 25, 25, 96)   82944       activation_1325[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1327 (Conv2D)            (None, 25, 25, 32)   6144        average_pooling2d_126[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1413_2 (Activation)  (None, 54, 54, 80)   0           batch_normalization_1413_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1321 (Batch (None, 25, 25, 64)   192         conv2d_1321[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1323 (Batch (None, 25, 25, 64)   192         conv2d_1323[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1326 (Batch (None, 25, 25, 96)   288         conv2d_1326[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1327 (Batch (None, 25, 25, 32)   96          conv2d_1327[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1414_2 (Conv2D)          (None, 52, 52, 192)  138240      activation_1413_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1321 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1321[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1323 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1323[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1326 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1326[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1327 (Activation)    (None, 25, 25, 32)   0           batch_normalization_1327[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1414_2 (Bat (None, 52, 52, 192)  576         conv2d_1414_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_1321[0][0]            \n",
            "                                                                 activation_1323[0][0]            \n",
            "                                                                 activation_1326[0][0]            \n",
            "                                                                 activation_1327[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1414_2 (Activation)  (None, 52, 52, 192)  0           batch_normalization_1414_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1331 (Conv2D)            (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_61_2 (MaxPooling2 (None, 25, 25, 192)  0           activation_1414_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1331 (Batch (None, 25, 25, 64)   192         conv2d_1331[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1418_2 (Conv2D)          (None, 25, 25, 64)   12288       max_pooling2d_61_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1331 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1331[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1418_2 (Bat (None, 25, 25, 64)   192         conv2d_1418_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1329 (Conv2D)            (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1332 (Conv2D)            (None, 25, 25, 96)   55296       activation_1331[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1418_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1418_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1329 (Batch (None, 25, 25, 48)   144         conv2d_1329[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1332 (Batch (None, 25, 25, 96)   288         conv2d_1332[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1416_2 (Conv2D)          (None, 25, 25, 48)   9216        max_pooling2d_61_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1419_2 (Conv2D)          (None, 25, 25, 96)   55296       activation_1418_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1329 (Activation)    (None, 25, 25, 48)   0           batch_normalization_1329[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1332 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1332[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_127 (AverageP (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1416_2 (Bat (None, 25, 25, 48)   144         conv2d_1416_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1419_2 (Bat (None, 25, 25, 96)   288         conv2d_1419_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1328 (Conv2D)            (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1330 (Conv2D)            (None, 25, 25, 64)   76800       activation_1329[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1333 (Conv2D)            (None, 25, 25, 96)   82944       activation_1332[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1334 (Conv2D)            (None, 25, 25, 64)   16384       average_pooling2d_127[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1416_2 (Activation)  (None, 25, 25, 48)   0           batch_normalization_1416_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1419_2 (Activation)  (None, 25, 25, 96)   0           batch_normalization_1419_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_135_2 (Averag (None, 25, 25, 192)  0           max_pooling2d_61_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1328 (Batch (None, 25, 25, 64)   192         conv2d_1328[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1330 (Batch (None, 25, 25, 64)   192         conv2d_1330[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1333 (Batch (None, 25, 25, 96)   288         conv2d_1333[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1334 (Batch (None, 25, 25, 64)   192         conv2d_1334[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1415_2 (Conv2D)          (None, 25, 25, 64)   12288       max_pooling2d_61_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1417_2 (Conv2D)          (None, 25, 25, 64)   76800       activation_1416_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1420_2 (Conv2D)          (None, 25, 25, 96)   82944       activation_1419_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1421_2 (Conv2D)          (None, 25, 25, 32)   6144        average_pooling2d_135_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1328 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1328[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1330 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1330[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1333 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1333[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1334 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1334[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1415_2 (Bat (None, 25, 25, 64)   192         conv2d_1415_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1417_2 (Bat (None, 25, 25, 64)   192         conv2d_1417_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1420_2 (Bat (None, 25, 25, 96)   288         conv2d_1420_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1421_2 (Bat (None, 25, 25, 32)   96          conv2d_1421_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_1328[0][0]            \n",
            "                                                                 activation_1330[0][0]            \n",
            "                                                                 activation_1333[0][0]            \n",
            "                                                                 activation_1334[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1415_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1415_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1417_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1417_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1420_2 (Activation)  (None, 25, 25, 96)   0           batch_normalization_1420_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1421_2 (Activation)  (None, 25, 25, 32)   0           batch_normalization_1421_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1338 (Conv2D)            (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0_2 (Concatenate)          (None, 25, 25, 256)  0           activation_1415_2[0][0]          \n",
            "                                                                 activation_1417_2[0][0]          \n",
            "                                                                 activation_1420_2[0][0]          \n",
            "                                                                 activation_1421_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1338 (Batch (None, 25, 25, 64)   192         conv2d_1338[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1425_2 (Conv2D)          (None, 25, 25, 64)   16384       mixed0_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1338 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1338[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1425_2 (Bat (None, 25, 25, 64)   192         conv2d_1425_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1336 (Conv2D)            (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1339 (Conv2D)            (None, 25, 25, 96)   55296       activation_1338[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1425_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1425_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1336 (Batch (None, 25, 25, 48)   144         conv2d_1336[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1339 (Batch (None, 25, 25, 96)   288         conv2d_1339[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1423_2 (Conv2D)          (None, 25, 25, 48)   12288       mixed0_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1426_2 (Conv2D)          (None, 25, 25, 96)   55296       activation_1425_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1336 (Activation)    (None, 25, 25, 48)   0           batch_normalization_1336[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1339 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1339[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_128 (AverageP (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1423_2 (Bat (None, 25, 25, 48)   144         conv2d_1423_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1426_2 (Bat (None, 25, 25, 96)   288         conv2d_1426_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1335 (Conv2D)            (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1337 (Conv2D)            (None, 25, 25, 64)   76800       activation_1336[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1340 (Conv2D)            (None, 25, 25, 96)   82944       activation_1339[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1341 (Conv2D)            (None, 25, 25, 64)   18432       average_pooling2d_128[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1423_2 (Activation)  (None, 25, 25, 48)   0           batch_normalization_1423_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1426_2 (Activation)  (None, 25, 25, 96)   0           batch_normalization_1426_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_136_2 (Averag (None, 25, 25, 256)  0           mixed0_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1335 (Batch (None, 25, 25, 64)   192         conv2d_1335[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1337 (Batch (None, 25, 25, 64)   192         conv2d_1337[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1340 (Batch (None, 25, 25, 96)   288         conv2d_1340[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1341 (Batch (None, 25, 25, 64)   192         conv2d_1341[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1422_2 (Conv2D)          (None, 25, 25, 64)   16384       mixed0_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1424_2 (Conv2D)          (None, 25, 25, 64)   76800       activation_1423_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1427_2 (Conv2D)          (None, 25, 25, 96)   82944       activation_1426_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1428_2 (Conv2D)          (None, 25, 25, 64)   16384       average_pooling2d_136_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1335 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1335[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1337 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1337[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1340 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1340[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1341 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1341[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1422_2 (Bat (None, 25, 25, 64)   192         conv2d_1422_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1424_2 (Bat (None, 25, 25, 64)   192         conv2d_1424_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1427_2 (Bat (None, 25, 25, 96)   288         conv2d_1427_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1428_2 (Bat (None, 25, 25, 64)   192         conv2d_1428_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_1335[0][0]            \n",
            "                                                                 activation_1337[0][0]            \n",
            "                                                                 activation_1340[0][0]            \n",
            "                                                                 activation_1341[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1422_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1422_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1424_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1424_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1427_2 (Activation)  (None, 25, 25, 96)   0           batch_normalization_1427_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1428_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1428_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1343 (Conv2D)            (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1_2 (Concatenate)          (None, 25, 25, 288)  0           activation_1422_2[0][0]          \n",
            "                                                                 activation_1424_2[0][0]          \n",
            "                                                                 activation_1427_2[0][0]          \n",
            "                                                                 activation_1428_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1343 (Batch (None, 25, 25, 64)   192         conv2d_1343[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1432_2 (Conv2D)          (None, 25, 25, 64)   18432       mixed1_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1343 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1343[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1432_2 (Bat (None, 25, 25, 64)   192         conv2d_1432_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1344 (Conv2D)            (None, 25, 25, 96)   55296       activation_1343[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1432_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1432_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1344 (Batch (None, 25, 25, 96)   288         conv2d_1344[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1430_2 (Conv2D)          (None, 25, 25, 48)   13824       mixed1_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1433_2 (Conv2D)          (None, 25, 25, 96)   55296       activation_1432_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1344 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1344[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1430_2 (Bat (None, 25, 25, 48)   144         conv2d_1430_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1433_2 (Bat (None, 25, 25, 96)   288         conv2d_1433_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1342 (Conv2D)            (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1345 (Conv2D)            (None, 12, 12, 96)   82944       activation_1344[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1430_2 (Activation)  (None, 25, 25, 48)   0           batch_normalization_1430_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1433_2 (Activation)  (None, 25, 25, 96)   0           batch_normalization_1433_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_137_2 (Averag (None, 25, 25, 288)  0           mixed1_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1342 (Batch (None, 12, 12, 384)  1152        conv2d_1342[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1345 (Batch (None, 12, 12, 96)   288         conv2d_1345[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1429_2 (Conv2D)          (None, 25, 25, 64)   18432       mixed1_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1431_2 (Conv2D)          (None, 25, 25, 64)   76800       activation_1430_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1434_2 (Conv2D)          (None, 25, 25, 96)   82944       activation_1433_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1435_2 (Conv2D)          (None, 25, 25, 64)   18432       average_pooling2d_137_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1342 (Activation)    (None, 12, 12, 384)  0           batch_normalization_1342[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1345 (Activation)    (None, 12, 12, 96)   0           batch_normalization_1345[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1429_2 (Bat (None, 25, 25, 64)   192         conv2d_1429_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1431_2 (Bat (None, 25, 25, 64)   192         conv2d_1431_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1434_2 (Bat (None, 25, 25, 96)   288         conv2d_1434_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1435_2 (Bat (None, 25, 25, 64)   192         conv2d_1435_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_1342[0][0]            \n",
            "                                                                 activation_1345[0][0]            \n",
            "                                                                 max_pooling2d_58[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1429_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1429_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1431_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1431_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1434_2 (Activation)  (None, 25, 25, 96)   0           batch_normalization_1434_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1435_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1435_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1350 (Conv2D)            (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2_2 (Concatenate)          (None, 25, 25, 288)  0           activation_1429_2[0][0]          \n",
            "                                                                 activation_1431_2[0][0]          \n",
            "                                                                 activation_1434_2[0][0]          \n",
            "                                                                 activation_1435_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1350 (Batch (None, 12, 12, 128)  384         conv2d_1350[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1437_2 (Conv2D)          (None, 25, 25, 64)   18432       mixed2_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1350 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1350[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1437_2 (Bat (None, 25, 25, 64)   192         conv2d_1437_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1351 (Conv2D)            (None, 12, 12, 128)  114688      activation_1350[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1437_2 (Activation)  (None, 25, 25, 64)   0           batch_normalization_1437_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1351 (Batch (None, 12, 12, 128)  384         conv2d_1351[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1438_2 (Conv2D)          (None, 25, 25, 96)   55296       activation_1437_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1351 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1351[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1438_2 (Bat (None, 25, 25, 96)   288         conv2d_1438_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1347 (Conv2D)            (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1352 (Conv2D)            (None, 12, 12, 128)  114688      activation_1351[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1438_2 (Activation)  (None, 25, 25, 96)   0           batch_normalization_1438_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1347 (Batch (None, 12, 12, 128)  384         conv2d_1347[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1352 (Batch (None, 12, 12, 128)  384         conv2d_1352[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1436_2 (Conv2D)          (None, 12, 12, 384)  995328      mixed2_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1439_2 (Conv2D)          (None, 12, 12, 96)   82944       activation_1438_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1347 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1347[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1352 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1352[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1436_2 (Bat (None, 12, 12, 384)  1152        conv2d_1436_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1439_2 (Bat (None, 12, 12, 96)   288         conv2d_1439_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1348 (Conv2D)            (None, 12, 12, 128)  114688      activation_1347[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1353 (Conv2D)            (None, 12, 12, 128)  114688      activation_1352[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1436_2 (Activation)  (None, 12, 12, 384)  0           batch_normalization_1436_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1439_2 (Activation)  (None, 12, 12, 96)   0           batch_normalization_1439_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_62_2 (MaxPooling2 (None, 12, 12, 288)  0           mixed2_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1348 (Batch (None, 12, 12, 128)  384         conv2d_1348[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1353 (Batch (None, 12, 12, 128)  384         conv2d_1353[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed3_2 (Concatenate)          (None, 12, 12, 768)  0           activation_1436_2[0][0]          \n",
            "                                                                 activation_1439_2[0][0]          \n",
            "                                                                 max_pooling2d_62_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1348 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1348[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1353 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1353[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_129 (AverageP (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1444_2 (Conv2D)          (None, 12, 12, 128)  98304       mixed3_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1346 (Conv2D)            (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1349 (Conv2D)            (None, 12, 12, 192)  172032      activation_1348[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1354 (Conv2D)            (None, 12, 12, 192)  172032      activation_1353[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1355 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_129[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1444_2 (Bat (None, 12, 12, 128)  384         conv2d_1444_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1346 (Batch (None, 12, 12, 192)  576         conv2d_1346[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1349 (Batch (None, 12, 12, 192)  576         conv2d_1349[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1354 (Batch (None, 12, 12, 192)  576         conv2d_1354[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1355 (Batch (None, 12, 12, 192)  576         conv2d_1355[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1444_2 (Activation)  (None, 12, 12, 128)  0           batch_normalization_1444_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1346 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1346[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1349 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1349[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1354 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1354[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1355 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1355[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1445_2 (Conv2D)          (None, 12, 12, 128)  114688      activation_1444_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_1346[0][0]            \n",
            "                                                                 activation_1349[0][0]            \n",
            "                                                                 activation_1354[0][0]            \n",
            "                                                                 activation_1355[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1445_2 (Bat (None, 12, 12, 128)  384         conv2d_1445_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1360 (Conv2D)            (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1445_2 (Activation)  (None, 12, 12, 128)  0           batch_normalization_1445_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1360 (Batch (None, 12, 12, 160)  480         conv2d_1360[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1441_2 (Conv2D)          (None, 12, 12, 128)  98304       mixed3_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1446_2 (Conv2D)          (None, 12, 12, 128)  114688      activation_1445_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1360 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1360[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1441_2 (Bat (None, 12, 12, 128)  384         conv2d_1441_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1446_2 (Bat (None, 12, 12, 128)  384         conv2d_1446_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1361 (Conv2D)            (None, 12, 12, 160)  179200      activation_1360[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1441_2 (Activation)  (None, 12, 12, 128)  0           batch_normalization_1441_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1446_2 (Activation)  (None, 12, 12, 128)  0           batch_normalization_1446_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1361 (Batch (None, 12, 12, 160)  480         conv2d_1361[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1442_2 (Conv2D)          (None, 12, 12, 128)  114688      activation_1441_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1447_2 (Conv2D)          (None, 12, 12, 128)  114688      activation_1446_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1361 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1361[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1442_2 (Bat (None, 12, 12, 128)  384         conv2d_1442_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1447_2 (Bat (None, 12, 12, 128)  384         conv2d_1447_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1357 (Conv2D)            (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1362 (Conv2D)            (None, 12, 12, 160)  179200      activation_1361[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1442_2 (Activation)  (None, 12, 12, 128)  0           batch_normalization_1442_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1447_2 (Activation)  (None, 12, 12, 128)  0           batch_normalization_1447_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_138_2 (Averag (None, 12, 12, 768)  0           mixed3_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1357 (Batch (None, 12, 12, 160)  480         conv2d_1357[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1362 (Batch (None, 12, 12, 160)  480         conv2d_1362[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1440_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed3_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1443_2 (Conv2D)          (None, 12, 12, 192)  172032      activation_1442_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1448_2 (Conv2D)          (None, 12, 12, 192)  172032      activation_1447_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1449_2 (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_138_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1357 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1357[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1362 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1362[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1440_2 (Bat (None, 12, 12, 192)  576         conv2d_1440_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1443_2 (Bat (None, 12, 12, 192)  576         conv2d_1443_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1448_2 (Bat (None, 12, 12, 192)  576         conv2d_1448_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1449_2 (Bat (None, 12, 12, 192)  576         conv2d_1449_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1358 (Conv2D)            (None, 12, 12, 160)  179200      activation_1357[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1363 (Conv2D)            (None, 12, 12, 160)  179200      activation_1362[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1440_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1440_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1443_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1443_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1448_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1448_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1449_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1449_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1358 (Batch (None, 12, 12, 160)  480         conv2d_1358[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1363 (Batch (None, 12, 12, 160)  480         conv2d_1363[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed4_2 (Concatenate)          (None, 12, 12, 768)  0           activation_1440_2[0][0]          \n",
            "                                                                 activation_1443_2[0][0]          \n",
            "                                                                 activation_1448_2[0][0]          \n",
            "                                                                 activation_1449_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1358 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1358[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1363 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1363[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_130 (AverageP (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1454_2 (Conv2D)          (None, 12, 12, 160)  122880      mixed4_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1356 (Conv2D)            (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1359 (Conv2D)            (None, 12, 12, 192)  215040      activation_1358[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1364 (Conv2D)            (None, 12, 12, 192)  215040      activation_1363[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1365 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_130[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1454_2 (Bat (None, 12, 12, 160)  480         conv2d_1454_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1356 (Batch (None, 12, 12, 192)  576         conv2d_1356[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1359 (Batch (None, 12, 12, 192)  576         conv2d_1359[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1364 (Batch (None, 12, 12, 192)  576         conv2d_1364[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1365 (Batch (None, 12, 12, 192)  576         conv2d_1365[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1454_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1454_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1356 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1356[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1359 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1359[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1364 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1364[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1365 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1365[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1455_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1454_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_1356[0][0]            \n",
            "                                                                 activation_1359[0][0]            \n",
            "                                                                 activation_1364[0][0]            \n",
            "                                                                 activation_1365[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1455_2 (Bat (None, 12, 12, 160)  480         conv2d_1455_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1370 (Conv2D)            (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1455_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1455_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1370 (Batch (None, 12, 12, 160)  480         conv2d_1370[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1451_2 (Conv2D)          (None, 12, 12, 160)  122880      mixed4_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1456_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1455_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1370 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1370[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1451_2 (Bat (None, 12, 12, 160)  480         conv2d_1451_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1456_2 (Bat (None, 12, 12, 160)  480         conv2d_1456_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1371 (Conv2D)            (None, 12, 12, 160)  179200      activation_1370[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1451_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1451_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1456_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1456_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1371 (Batch (None, 12, 12, 160)  480         conv2d_1371[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1452_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1451_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1457_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1456_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1371 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1371[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1452_2 (Bat (None, 12, 12, 160)  480         conv2d_1452_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1457_2 (Bat (None, 12, 12, 160)  480         conv2d_1457_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1367 (Conv2D)            (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1372 (Conv2D)            (None, 12, 12, 160)  179200      activation_1371[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1452_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1452_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1457_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1457_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_139_2 (Averag (None, 12, 12, 768)  0           mixed4_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1367 (Batch (None, 12, 12, 160)  480         conv2d_1367[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1372 (Batch (None, 12, 12, 160)  480         conv2d_1372[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1450_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed4_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1453_2 (Conv2D)          (None, 12, 12, 192)  215040      activation_1452_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1458_2 (Conv2D)          (None, 12, 12, 192)  215040      activation_1457_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1459_2 (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_139_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1367 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1367[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1372 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1372[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1450_2 (Bat (None, 12, 12, 192)  576         conv2d_1450_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1453_2 (Bat (None, 12, 12, 192)  576         conv2d_1453_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1458_2 (Bat (None, 12, 12, 192)  576         conv2d_1458_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1459_2 (Bat (None, 12, 12, 192)  576         conv2d_1459_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1368 (Conv2D)            (None, 12, 12, 160)  179200      activation_1367[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1373 (Conv2D)            (None, 12, 12, 160)  179200      activation_1372[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1450_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1450_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1453_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1453_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1458_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1458_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1459_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1459_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1368 (Batch (None, 12, 12, 160)  480         conv2d_1368[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1373 (Batch (None, 12, 12, 160)  480         conv2d_1373[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed5_2 (Concatenate)          (None, 12, 12, 768)  0           activation_1450_2[0][0]          \n",
            "                                                                 activation_1453_2[0][0]          \n",
            "                                                                 activation_1458_2[0][0]          \n",
            "                                                                 activation_1459_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1368 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1368[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1373 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1373[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_131 (AverageP (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1464_2 (Conv2D)          (None, 12, 12, 160)  122880      mixed5_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1366 (Conv2D)            (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1369 (Conv2D)            (None, 12, 12, 192)  215040      activation_1368[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1374 (Conv2D)            (None, 12, 12, 192)  215040      activation_1373[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1375 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_131[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1464_2 (Bat (None, 12, 12, 160)  480         conv2d_1464_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1366 (Batch (None, 12, 12, 192)  576         conv2d_1366[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1369 (Batch (None, 12, 12, 192)  576         conv2d_1369[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1374 (Batch (None, 12, 12, 192)  576         conv2d_1374[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1375 (Batch (None, 12, 12, 192)  576         conv2d_1375[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1464_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1464_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1366 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1366[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1369 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1369[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1374 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1374[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1375 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1375[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1465_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1464_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_1366[0][0]            \n",
            "                                                                 activation_1369[0][0]            \n",
            "                                                                 activation_1374[0][0]            \n",
            "                                                                 activation_1375[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1465_2 (Bat (None, 12, 12, 160)  480         conv2d_1465_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1380 (Conv2D)            (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1465_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1465_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1380 (Batch (None, 12, 12, 192)  576         conv2d_1380[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1461_2 (Conv2D)          (None, 12, 12, 160)  122880      mixed5_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1466_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1465_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1380 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1380[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1461_2 (Bat (None, 12, 12, 160)  480         conv2d_1461_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1466_2 (Bat (None, 12, 12, 160)  480         conv2d_1466_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1381 (Conv2D)            (None, 12, 12, 192)  258048      activation_1380[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1461_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1461_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1466_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1466_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1381 (Batch (None, 12, 12, 192)  576         conv2d_1381[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1462_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1461_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1467_2 (Conv2D)          (None, 12, 12, 160)  179200      activation_1466_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1381 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1381[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1462_2 (Bat (None, 12, 12, 160)  480         conv2d_1462_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1467_2 (Bat (None, 12, 12, 160)  480         conv2d_1467_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1377 (Conv2D)            (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1382 (Conv2D)            (None, 12, 12, 192)  258048      activation_1381[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1462_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1462_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1467_2 (Activation)  (None, 12, 12, 160)  0           batch_normalization_1467_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_140_2 (Averag (None, 12, 12, 768)  0           mixed5_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1377 (Batch (None, 12, 12, 192)  576         conv2d_1377[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1382 (Batch (None, 12, 12, 192)  576         conv2d_1382[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1460_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed5_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1463_2 (Conv2D)          (None, 12, 12, 192)  215040      activation_1462_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1468_2 (Conv2D)          (None, 12, 12, 192)  215040      activation_1467_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1469_2 (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_140_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1377 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1377[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1382 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1382[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1460_2 (Bat (None, 12, 12, 192)  576         conv2d_1460_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1463_2 (Bat (None, 12, 12, 192)  576         conv2d_1463_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1468_2 (Bat (None, 12, 12, 192)  576         conv2d_1468_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1469_2 (Bat (None, 12, 12, 192)  576         conv2d_1469_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1378 (Conv2D)            (None, 12, 12, 192)  258048      activation_1377[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1383 (Conv2D)            (None, 12, 12, 192)  258048      activation_1382[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1460_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1460_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1463_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1463_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1468_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1468_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1469_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1469_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1378 (Batch (None, 12, 12, 192)  576         conv2d_1378[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1383 (Batch (None, 12, 12, 192)  576         conv2d_1383[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed6_2 (Concatenate)          (None, 12, 12, 768)  0           activation_1460_2[0][0]          \n",
            "                                                                 activation_1463_2[0][0]          \n",
            "                                                                 activation_1468_2[0][0]          \n",
            "                                                                 activation_1469_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1378 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1378[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1383 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1383[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_132 (AverageP (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1474_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed6_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1376 (Conv2D)            (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1379 (Conv2D)            (None, 12, 12, 192)  258048      activation_1378[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1384 (Conv2D)            (None, 12, 12, 192)  258048      activation_1383[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1385 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_132[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1474_2 (Bat (None, 12, 12, 192)  576         conv2d_1474_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1376 (Batch (None, 12, 12, 192)  576         conv2d_1376[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1379 (Batch (None, 12, 12, 192)  576         conv2d_1379[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1384 (Batch (None, 12, 12, 192)  576         conv2d_1384[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1385 (Batch (None, 12, 12, 192)  576         conv2d_1385[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1474_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1474_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1376 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1376[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1379 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1379[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1384 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1384[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1385 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1385[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1475_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1474_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_1376[0][0]            \n",
            "                                                                 activation_1379[0][0]            \n",
            "                                                                 activation_1384[0][0]            \n",
            "                                                                 activation_1385[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1475_2 (Bat (None, 12, 12, 192)  576         conv2d_1475_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1388 (Conv2D)            (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1475_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1475_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1388 (Batch (None, 12, 12, 192)  576         conv2d_1388[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1471_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed6_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1476_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1475_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1388 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1388[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1471_2 (Bat (None, 12, 12, 192)  576         conv2d_1471_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1476_2 (Bat (None, 12, 12, 192)  576         conv2d_1476_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1389 (Conv2D)            (None, 12, 12, 192)  258048      activation_1388[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1471_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1471_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1476_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1476_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1389 (Batch (None, 12, 12, 192)  576         conv2d_1389[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1472_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1471_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1477_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1476_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1389 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1389[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1472_2 (Bat (None, 12, 12, 192)  576         conv2d_1472_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1477_2 (Bat (None, 12, 12, 192)  576         conv2d_1477_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1386 (Conv2D)            (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1390 (Conv2D)            (None, 12, 12, 192)  258048      activation_1389[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1472_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1472_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1477_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1477_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_141_2 (Averag (None, 12, 12, 768)  0           mixed6_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1386 (Batch (None, 12, 12, 192)  576         conv2d_1386[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1390 (Batch (None, 12, 12, 192)  576         conv2d_1390[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1470_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed6_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1473_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1472_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1478_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1477_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1479_2 (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_141_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1386 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1386[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1390 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1390[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1470_2 (Bat (None, 12, 12, 192)  576         conv2d_1470_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1473_2 (Bat (None, 12, 12, 192)  576         conv2d_1473_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1478_2 (Bat (None, 12, 12, 192)  576         conv2d_1478_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1479_2 (Bat (None, 12, 12, 192)  576         conv2d_1479_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1387 (Conv2D)            (None, 5, 5, 320)    552960      activation_1386[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1391 (Conv2D)            (None, 5, 5, 192)    331776      activation_1390[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1470_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1470_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1473_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1473_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1478_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1478_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1479_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1479_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1387 (Batch (None, 5, 5, 320)    960         conv2d_1387[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1391 (Batch (None, 5, 5, 192)    576         conv2d_1391[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixed7_2 (Concatenate)          (None, 12, 12, 768)  0           activation_1470_2[0][0]          \n",
            "                                                                 activation_1473_2[0][0]          \n",
            "                                                                 activation_1478_2[0][0]          \n",
            "                                                                 activation_1479_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1387 (Activation)    (None, 5, 5, 320)    0           batch_normalization_1387[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1391 (Activation)    (None, 5, 5, 192)    0           batch_normalization_1391[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1482_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed7_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_1387[0][0]            \n",
            "                                                                 activation_1391[0][0]            \n",
            "                                                                 max_pooling2d_59[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1482_2 (Bat (None, 12, 12, 192)  576         conv2d_1482_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1396 (Conv2D)            (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1482_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1482_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1396 (Batch (None, 5, 5, 448)    1344        conv2d_1396[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1483_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1482_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1396 (Activation)    (None, 5, 5, 448)    0           batch_normalization_1396[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1483_2 (Bat (None, 12, 12, 192)  576         conv2d_1483_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1393 (Conv2D)            (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1397 (Conv2D)            (None, 5, 5, 384)    1548288     activation_1396[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1483_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1483_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1393 (Batch (None, 5, 5, 384)    1152        conv2d_1393[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1397 (Batch (None, 5, 5, 384)    1152        conv2d_1397[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1480_2 (Conv2D)          (None, 12, 12, 192)  147456      mixed7_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1484_2 (Conv2D)          (None, 12, 12, 192)  258048      activation_1483_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1393 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1393[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1397 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1397[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1480_2 (Bat (None, 12, 12, 192)  576         conv2d_1480_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1484_2 (Bat (None, 12, 12, 192)  576         conv2d_1484_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1394 (Conv2D)            (None, 5, 5, 384)    442368      activation_1393[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1395 (Conv2D)            (None, 5, 5, 384)    442368      activation_1393[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1398 (Conv2D)            (None, 5, 5, 384)    442368      activation_1397[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1399 (Conv2D)            (None, 5, 5, 384)    442368      activation_1397[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_133 (AverageP (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1480_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1480_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1484_2 (Activation)  (None, 12, 12, 192)  0           batch_normalization_1484_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1392 (Conv2D)            (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1394 (Batch (None, 5, 5, 384)    1152        conv2d_1394[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1395 (Batch (None, 5, 5, 384)    1152        conv2d_1395[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1398 (Batch (None, 5, 5, 384)    1152        conv2d_1398[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1399 (Batch (None, 5, 5, 384)    1152        conv2d_1399[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1400 (Conv2D)            (None, 5, 5, 192)    245760      average_pooling2d_133[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1481_2 (Conv2D)          (None, 5, 5, 320)    552960      activation_1480_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1485_2 (Conv2D)          (None, 5, 5, 192)    331776      activation_1484_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1392 (Batch (None, 5, 5, 320)    960         conv2d_1392[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1394 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1394[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1395 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1395[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1398 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1398[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1399 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1399[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1400 (Batch (None, 5, 5, 192)    576         conv2d_1400[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1481_2 (Bat (None, 5, 5, 320)    960         conv2d_1481_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1485_2 (Bat (None, 5, 5, 192)    576         conv2d_1485_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1392 (Activation)    (None, 5, 5, 320)    0           batch_normalization_1392[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_1394[0][0]            \n",
            "                                                                 activation_1395[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 5, 5, 768)    0           activation_1398[0][0]            \n",
            "                                                                 activation_1399[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1400 (Activation)    (None, 5, 5, 192)    0           batch_normalization_1400[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1481_2 (Activation)  (None, 5, 5, 320)    0           batch_normalization_1481_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1485_2 (Activation)  (None, 5, 5, 192)    0           batch_normalization_1485_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_63_2 (MaxPooling2 (None, 5, 5, 768)    0           mixed7_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_1392[0][0]            \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_33[0][0]             \n",
            "                                                                 activation_1400[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed8_2 (Concatenate)          (None, 5, 5, 1280)   0           activation_1481_2[0][0]          \n",
            "                                                                 activation_1485_2[0][0]          \n",
            "                                                                 max_pooling2d_63_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1405 (Conv2D)            (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1490_2 (Conv2D)          (None, 5, 5, 448)    573440      mixed8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1405 (Batch (None, 5, 5, 448)    1344        conv2d_1405[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1490_2 (Bat (None, 5, 5, 448)    1344        conv2d_1490_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1405 (Activation)    (None, 5, 5, 448)    0           batch_normalization_1405[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1490_2 (Activation)  (None, 5, 5, 448)    0           batch_normalization_1490_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1402 (Conv2D)            (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1406 (Conv2D)            (None, 5, 5, 384)    1548288     activation_1405[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1487_2 (Conv2D)          (None, 5, 5, 384)    491520      mixed8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1491_2 (Conv2D)          (None, 5, 5, 384)    1548288     activation_1490_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1402 (Batch (None, 5, 5, 384)    1152        conv2d_1402[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1406 (Batch (None, 5, 5, 384)    1152        conv2d_1406[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1487_2 (Bat (None, 5, 5, 384)    1152        conv2d_1487_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1491_2 (Bat (None, 5, 5, 384)    1152        conv2d_1491_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1402 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1402[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1406 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1406[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1487_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1487_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1491_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1491_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1403 (Conv2D)            (None, 5, 5, 384)    442368      activation_1402[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1404 (Conv2D)            (None, 5, 5, 384)    442368      activation_1402[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1407 (Conv2D)            (None, 5, 5, 384)    442368      activation_1406[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1408 (Conv2D)            (None, 5, 5, 384)    442368      activation_1406[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_134 (AverageP (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1488_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1487_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1489_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1487_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1492_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1491_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1493_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1491_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_142_2 (Averag (None, 5, 5, 1280)   0           mixed8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1401 (Conv2D)            (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1403 (Batch (None, 5, 5, 384)    1152        conv2d_1403[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1404 (Batch (None, 5, 5, 384)    1152        conv2d_1404[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1407 (Batch (None, 5, 5, 384)    1152        conv2d_1407[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1408 (Batch (None, 5, 5, 384)    1152        conv2d_1408[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1409 (Conv2D)            (None, 5, 5, 192)    393216      average_pooling2d_134[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1486_2 (Conv2D)          (None, 5, 5, 320)    409600      mixed8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1488_2 (Bat (None, 5, 5, 384)    1152        conv2d_1488_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1489_2 (Bat (None, 5, 5, 384)    1152        conv2d_1489_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1492_2 (Bat (None, 5, 5, 384)    1152        conv2d_1492_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1493_2 (Bat (None, 5, 5, 384)    1152        conv2d_1493_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1494_2 (Conv2D)          (None, 5, 5, 192)    245760      average_pooling2d_142_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1401 (Batch (None, 5, 5, 320)    960         conv2d_1401[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1403 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1403[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1404 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1404[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1407 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1407[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1408 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1408[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1409 (Batch (None, 5, 5, 192)    576         conv2d_1409[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1486_2 (Bat (None, 5, 5, 320)    960         conv2d_1486_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1488_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1488_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1489_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1489_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1492_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1492_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1493_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1493_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1494_2 (Bat (None, 5, 5, 192)    576         conv2d_1494_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1401 (Activation)    (None, 5, 5, 320)    0           batch_normalization_1401[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_1403[0][0]            \n",
            "                                                                 activation_1404[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 5, 5, 768)    0           activation_1407[0][0]            \n",
            "                                                                 activation_1408[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1409 (Activation)    (None, 5, 5, 192)    0           batch_normalization_1409[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1486_2 (Activation)  (None, 5, 5, 320)    0           batch_normalization_1486_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0_2 (Concatenate)        (None, 5, 5, 768)    0           activation_1488_2[0][0]          \n",
            "                                                                 activation_1489_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35_2 (Concatenate)  (None, 5, 5, 768)    0           activation_1492_2[0][0]          \n",
            "                                                                 activation_1493_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1494_2 (Activation)  (None, 5, 5, 192)    0           batch_normalization_1494_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_1401[0][0]            \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_34[0][0]             \n",
            "                                                                 activation_1409[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_2 (Concatenate)          (None, 5, 5, 2048)   0           activation_1486_2[0][0]          \n",
            "                                                                 mixed9_0_2[0][0]                 \n",
            "                                                                 concatenate_35_2[0][0]           \n",
            "                                                                 activation_1494_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv_class (Conv2D)             (None, 5, 5, 10)     20490       mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1499_2 (Conv2D)          (None, 5, 5, 448)    917504      mixed9_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_12 (Gl (None, 10)           0           conv_class[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1499_2 (Bat (None, 5, 5, 448)    1344        conv2d_1499_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "output_1 (Softmax)              (None, 10)           0           global_average_pooling2d_12[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "activation_1499_2 (Activation)  (None, 5, 5, 448)    0           batch_normalization_1499_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1496_2 (Conv2D)          (None, 5, 5, 384)    786432      mixed9_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1500_2 (Conv2D)          (None, 5, 5, 384)    1548288     activation_1499_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lambda_61 (Lambda)              (None, 1, 10)        0           output_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1496_2 (Bat (None, 5, 5, 384)    1152        conv2d_1496_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1500_2 (Bat (None, 5, 5, 384)    1152        conv2d_1500_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_62 (Lambda)              (None, 1, 1, 10)     0           lambda_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1496_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1496_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1500_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1500_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "lambda_63 (Lambda)              (None, 5, 1, 10)     0           lambda_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1497_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1496_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1498_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1496_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1501_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1500_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1502_2 (Conv2D)          (None, 5, 5, 384)    442368      activation_1500_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_143_2 (Averag (None, 5, 5, 2048)   0           mixed9_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_65 (Lambda)              (None, 5, 5, 10)     0           conv_class[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_64 (Lambda)              (None, 5, 5, 10)     0           lambda_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1495_2 (Conv2D)          (None, 5, 5, 320)    655360      mixed9_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1497_2 (Bat (None, 5, 5, 384)    1152        conv2d_1497_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1498_2 (Bat (None, 5, 5, 384)    1152        conv2d_1498_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1501_2 (Bat (None, 5, 5, 384)    1152        conv2d_1501_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1502_2 (Bat (None, 5, 5, 384)    1152        conv2d_1502_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1503_2 (Conv2D)          (None, 5, 5, 192)    393216      average_pooling2d_143_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_14 (Multiply)          (None, 5, 5, 10)     0           lambda_65[0][0]                  \n",
            "                                                                 lambda_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_67 (Lambda)              (None, 5, 5, 1)      0           lambda_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1495_2 (Bat (None, 5, 5, 320)    960         conv2d_1495_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1497_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1497_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1498_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1498_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1501_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1501_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_1502_2 (Activation)  (None, 5, 5, 384)    0           batch_normalization_1502_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1503_2 (Bat (None, 5, 5, 192)    576         conv2d_1503_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_66 (Lambda)              (None, 5, 5)         0           multiply_14[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "scale_transform_s_and_1 (Conv2D (None, 5, 5, 1)      2           lambda_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1495_2 (Activation)  (None, 5, 5, 320)    0           batch_normalization_1495_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1_2 (Concatenate)        (None, 5, 5, 768)    0           activation_1497_2[0][0]          \n",
            "                                                                 activation_1498_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36_2 (Concatenate)  (None, 5, 5, 768)    0           activation_1501_2[0][0]          \n",
            "                                                                 activation_1502_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1503_2 (Activation)  (None, 5, 5, 192)    0           batch_normalization_1503_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "lambda_68 (Lambda)              (None, 5, 5, 1)      0           lambda_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "scale_transform_s_and_2 (Conv2D (None, 5, 5, 1)      2           scale_transform_s_and_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10_2 (Concatenate)         (None, 5, 5, 2048)   0           activation_1495_2[0][0]          \n",
            "                                                                 mixed9_1_2[0][0]                 \n",
            "                                                                 concatenate_36_2[0][0]           \n",
            "                                                                 activation_1503_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "multiply_15 (Multiply)          (None, 5, 5, 1)      0           lambda_68[0][0]                  \n",
            "                                                                 scale_transform_s_and_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "scale_transform_1 (Conv2D)      (None, 5, 5, 1)      2           multiply_15[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 5, 5, 4096)   0           mixed10[0][0]                    \n",
            "                                                                 mixed10_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "scale_transform_2 (Conv2D)      (None, 5, 5, 1)      2           scale_transform_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_13 (Gl (None, 4096)         0           concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_class_filtered (Conv2D)    (None, 5, 5, 10)     20490       mixed10_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mask (Lambda)                   (None, 5, 5, 1)      0           scale_transform_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1024)         4195328     global_average_pooling2d_13[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "global_attention_pooling2d_8 (G (None, 10)           0           conv_class_filtered[0][0]        \n",
            "                                                                 mask[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           10250       dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output_2 (Softmax)              (None, 10)           0           global_attention_pooling2d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "output_3 (Softmax)              (None, 10)           0           dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_69 (Lambda)              (None, 10)           0           dense_11[0][0]                   \n",
            "                                                                 global_attention_pooling2d_8[0][0\n",
            "                                                                 output_3[0][0]                   \n",
            "                                                                 output_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output_5 (Softmax)              (None, 10)           0           lambda_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Rank_loss (Lambda)              (None, 2, 10)        0           output_1[0][0]                   \n",
            "                                                                 output_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "M_loss (Lambda)                 (None, 1)            0           mask[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "S_and_loss (Lambda)             (None, 1)            0           scale_transform_s_and_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Cross_network_similarity_loss ( (None, 2, 10)        0           Rank_loss[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Rank_2_loss (Lambda)            (None, 2, 10)        0           output_1[0][0]                   \n",
            "                                                                 output_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Rank_3_loss (Lambda)            (None, 2, 10)        0           output_2[0][0]                   \n",
            "                                                                 output_5[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 47,852,134\n",
            "Trainable params: 47,783,270\n",
            "Non-trainable params: 68,864\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOa5FXnfkPVF"
      },
      "source": [
        "from keras import optimizers\r\n",
        "model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy',\r\n",
        "                        'categorical_crossentropy',\r\n",
        "                        'mean_squared_error', 'mean_squared_error',\r\n",
        "                        rank_loss,\r\n",
        "                        cross_network_similarity_loss,\r\n",
        "                        rank_loss,\r\n",
        "                        rank_loss,\r\n",
        "                        ],\r\n",
        "                  # optimizer=optimizers.SGD(lr=0.0001, momentum=0.9, decay=0.0, nesterov=False),\r\n",
        "                  optimizer=optimizers.RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08, decay=0.000001),\r\n",
        "                  metrics={'output_1': ['accuracy', 'top_k_categorical_accuracy'],\r\n",
        "                           'output_2': ['accuracy', 'top_k_categorical_accuracy'],\r\n",
        "                           'output_3': ['accuracy', 'top_k_categorical_accuracy'],\r\n",
        "                           # 'output_4': ['accuracy', 'top_k_categorical_accuracy'],\r\n",
        "                           'output_5': ['accuracy', 'top_k_categorical_accuracy'],\r\n",
        "                           })"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR9fH7bcmTVz"
      },
      "source": [
        "import warnings\r\n",
        "\r\n",
        "import keras.callbacks as KC\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "try:\r\n",
        "    import requests\r\n",
        "except ImportError:\r\n",
        "    requests = None\r\n",
        "\r\n",
        "\r\n",
        "class ModelCheckpoint(KC.Callback):\r\n",
        "    \"\"\"Save the model after every epoch.\r\n",
        "    `filepath` can contain named formatting options,\r\n",
        "    which will be filled the value of `epoch` and\r\n",
        "    keys in `logs` (passed in `on_epoch_end`).\r\n",
        "    For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,\r\n",
        "    then the model checkpoints will be saved with the epoch number and\r\n",
        "    the validation loss in the filename.\r\n",
        "    # Arguments\r\n",
        "        filepath: string, path to save the model file.\r\n",
        "        monitor: quantity to monitor.\r\n",
        "        verbose: verbosity mode, 0 or 1.\r\n",
        "        save_best_only: if `save_best_only=True`,\r\n",
        "            the latest best model according to\r\n",
        "            the quantity monitored will not be overwritten.\r\n",
        "        mode: one of {auto, min, max}.\r\n",
        "            If `save_best_only=True`, the decision\r\n",
        "            to overwrite the current save file is made\r\n",
        "            based on either the maximization or the\r\n",
        "            minimization of the monitored quantity. For `val_acc`,\r\n",
        "            this should be `max`, for `val_loss` this should\r\n",
        "            be `min`, etc. In `auto` mode, the direction is\r\n",
        "            automatically inferred from the name of the monitored quantity.\r\n",
        "        save_weights_only: if True, then only the model's weights will be\r\n",
        "            saved (`model.save_weights(filepath)`), else the full model\r\n",
        "            is saved (`model.save(filepath)`).\r\n",
        "        period: Interval (number of epochs) between checkpoints.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, filepath, single_model, monitor='val_loss', verbose=0,\r\n",
        "                 save_best_only=False, save_weights_only=False,\r\n",
        "                 mode='auto', period=1):\r\n",
        "        super(ModelCheckpoint, self).__init__()\r\n",
        "        self.monitor = monitor\r\n",
        "        self.verbose = verbose\r\n",
        "        self.filepath = filepath\r\n",
        "        self.save_best_only = save_best_only\r\n",
        "        self.save_weights_only = save_weights_only\r\n",
        "        self.period = period\r\n",
        "        self.epochs_since_last_save = 0\r\n",
        "        self.single_model = single_model\r\n",
        "\r\n",
        "        if mode not in ['auto', 'min', 'max']:\r\n",
        "            warnings.warn('ModelCheckpoint mode %s is unknown, '\r\n",
        "                          'fallback to auto mode.' % (mode),\r\n",
        "                          RuntimeWarning)\r\n",
        "            mode = 'auto'\r\n",
        "\r\n",
        "        if mode == 'min':\r\n",
        "            self.monitor_op = np.less\r\n",
        "            self.best = np.Inf\r\n",
        "        elif mode == 'max':\r\n",
        "            self.monitor_op = np.greater\r\n",
        "            self.best = -np.Inf\r\n",
        "        else:\r\n",
        "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\r\n",
        "                self.monitor_op = np.greater\r\n",
        "                self.best = -np.Inf\r\n",
        "            else:\r\n",
        "                self.monitor_op = np.less\r\n",
        "                self.best = np.Inf\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "        logs = logs or {}\r\n",
        "        self.epochs_since_last_save += 1\r\n",
        "        if self.epochs_since_last_save >= self.period:\r\n",
        "            self.epochs_since_last_save = 0\r\n",
        "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\r\n",
        "            if self.save_best_only:\r\n",
        "                current = logs.get(self.monitor)\r\n",
        "                if current is None:\r\n",
        "                    warnings.warn('Can save best model only with %s available, '\r\n",
        "                                  'skipping.' % (self.monitor), RuntimeWarning)\r\n",
        "                else:\r\n",
        "                    if self.monitor_op(current, self.best):\r\n",
        "                        if self.verbose > 0:\r\n",
        "                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\r\n",
        "                                  ' saving model to %s'\r\n",
        "                                  % (epoch + 1, self.monitor, self.best,\r\n",
        "                                     current, filepath))\r\n",
        "                        self.best = current\r\n",
        "                        if self.save_weights_only:\r\n",
        "                            self.single_model.save_weights(filepath, overwrite=True)\r\n",
        "                        else:\r\n",
        "                            self.single_model.save(filepath, overwrite=True)\r\n",
        "                    else:\r\n",
        "                        if self.verbose > 0:\r\n",
        "                            print('\\nEpoch %05d: %s did not improve' %\r\n",
        "                                  (epoch + 1, self.monitor))\r\n",
        "            else:\r\n",
        "                if self.verbose > 0:\r\n",
        "                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\r\n",
        "                if self.save_weights_only:\r\n",
        "                    self.single_model.save_weights(filepath, overwrite=True)\r\n",
        "                else:\r\n",
        "                    self.single_model.save(filepath, overwrite=True)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ35t71PmX3S"
      },
      "source": [
        "import os\r\n",
        "file_path = os.getcwd()+'/best_weights.hdf5'"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSMyw8ZqkgnW"
      },
      "source": [
        "checkpoint = ModelCheckpoint(file_path, single_model=model, monitor='val_output_5_acc',\r\n",
        "                                              verbose=1, save_best_only=True, save_weights_only=True, mode='max')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo9Ic3Cpm5Ye"
      },
      "source": [
        "    model.fit_generator(\r\n",
        "        train_generator,\r\n",
        "        steps_per_epoch=(train_generator.n // batch_size),\r\n",
        "        epochs=epochs,\r\n",
        "        validation_data=validation_generator,\r\n",
        "        validation_steps=math.ceil(float(validation_generator.n) // batch_size),\r\n",
        "        callbacks=callbacks_list,\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sal4cgVSpFro"
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0aNDtPco-dR"
      },
      "source": [
        "img_train = tfds.load(\r\n",
        "    'caltech_birds2011',\r\n",
        "    split=['test'],\r\n",
        "    batch_size=-1,\r\n",
        "    as_supervised=True,\r\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_sOKbQvrAlC"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz5rRIy7pe5K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}